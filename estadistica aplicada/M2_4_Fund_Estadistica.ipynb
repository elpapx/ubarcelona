{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M2_4_Fund_Estadistica.ipynb","provenance":[{"file_id":"15YU4x9Eq18_KOUBlzwq1oz4G9vABFahI","timestamp":1600263939197},{"file_id":"1aUbU28hJ9cmjZ-XmFCUcWGGPd7i9GaxU","timestamp":1600184038448}],"collapsed_sections":["nSVq03VwEUdA"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qRNdbPLqB7hQ"},"source":["# **Fundamentos de Estad√≠stica**\n","\n","---\n","---\n","<!-- Star Wars: Episodio II - El ataque de los clones -->\n","\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/5/52/Sw-ep2-logo.png' width=\"500\" height=\"150\" />\n","</figure></center>\n","\n","\n","Fuente de la imagen: [https://es.wikipedia.org](https://es.wikipedia.org/wiki/Star_Wars:_Episodio_II_-_El_ataque_de_los_clones)\n"]},{"cell_type":"markdown","metadata":{"id":"c3MfC8t0mHx5"},"source":["# **√çndice**\n","\n","---\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"l-p6H-isRNjh"},"source":["> [Fundamentos de Estad√≠stica](#scrollTo=qRNdbPLqB7hQ&line=6&uniqifier=1)\n","<br>\n",">>\n",">> [4 - Regresi√≥n y Correlaci√≥n](#scrollTo=EbuVsgDmrxZF&line=29&uniqifier=1) \\\\\n",">>> [4.1. L√≠nea general de regresi√≥n](#scrollTo=AhVjQVR_ySKI&line=1&uniqifier=1) \\\\\n",">>>> [4.1.1. Recta de Regresi√≥n Y sobre X](#scrollTo=WV7hPh723_HU&line=1&uniqifier=1) \\\\\n",">>>> [4.1.2. Recta de Regresi√≥n X sobre Y](#scrollTo=wzFKXg5UajN8&line=14&uniqifier=1) \\\\\n",">>>\n",">>> [4.2. Correlaci√≥n](#scrollTo=L9AaPrzWdg78&line=1&uniqifier=1) \\\\\n",">>>> [4.2.1. Coeficiente de correlaci√≥n lineal de Pearson](#scrollTo=hD0-YpJseUp5&line=50&uniqifier=1) \\\\\n",">>>> [4.2.2. Bondad de ajuste](#scrollTo=72C-u_fTHsTK&line=42&uniqifier=1) \\\\\n",">>>\n",">>> [4.3. Regresi√≥n No-Lineal](#scrollTo=NkBW7AsF0H8v&line=1&uniqifier=1) \\\\\n",">>>\n",">>> [4.4. Correlaci√≥n entre atributos](#scrollTo=HAbrrvPCaFF6&line=5&uniqifier=1) \\\\\n",">>>> [4.4.1. Coeficiente de correlaci√≥n de Spearman](#scrollTo=r92xwqrAbBFs&line=72&uniqifier=1) \\\\\n",">>>> [4.4.2. Coeficiente de correlaci√≥n de Kendall](#scrollTo=9WNs96BPHRwO&line=50&uniqifier=1) \\\\\n",">>>> [4.4.3. Chi-cuadrado](#scrollTo=011UsSrNH8Nk&line=30&uniqifier=1) \\\\\n",">>>> [4.4.4. Coeficiente de contingencia](#scrollTo=R8Ddy0xmHxPd&line=47&uniqifier=1) \\\\\n",">>>\n",">>> [Actividad: Consumo hogar medio](#scrollTo=Z2-zAshEpxSS&line=1&uniqifier=1) \\\\\n",">>>> [Soluci√≥n](#scrollTo=FBWc0hGBjxgW) \\\\\n",">>>\n",">>\n",">> [Ideas Clave](#scrollTo=fCEAHetVKufX&line=4&uniqifier=1) \n","\n","<br>\n","\n","< [3 - Estad√≠stica Descriptiva Bidimensional](https://colab.research.google.com/drive/1zkj_jhGyKEAzCq4WEZ-HMbDlCxtlVCYO?usp=sharing) | \n","[5 - Introducci√≥n al C√°lculo de Probabilidades](https://colab.research.google.com/drive/1WMQK4bpcZ1obFZe2mN70dJlJWKBBOVQ_?usp=sharing) >"]},{"cell_type":"markdown","metadata":{"id":"EbuVsgDmrxZF"},"source":["# 4 - Regresi√≥n y Correlaci√≥n\n","\n","Su **objetivo** es determinar si existe **relaci√≥n entre dos variables**. Por ejemplo, si tenemos dos variables como el peso y la altura, o la edad y el salario... se trata de dar respuesta y averiguar si una variable influye en la otra. Por ejemplo:\n","-\t¬øInfluye la altura en el peso de un individuo?\n","-\t¬øInfluye la edad en la renta que percibe alguien?\n","-\t¬øInfluye el consumo de tabaco en el c√°ncer de pulm√≥n?\n","- ¬øInfluye el consumo de alcohol en el c√°ncer de pulm√≥n?\n","\n","Para dar respuesta a este tipo de preguntas, contamos con dos teor√≠as:\n","\n"," 1. **Teor√≠a de Regresi√≥n**: \n","  * Consiste en encontrar **una funci√≥n que se ajuste lo mejor posible a un conjunto de puntos observados**. Es decir, consiste en la **b√∫squeda** de una funci√≥n que exprese, lo mejor , el **tipo de relaci√≥n entre dos o m√°s variables.**\n","  \n","  * Gr√°ficamente, equivale a encontrar una curva que, aunque no pase por todos los puntos, est√© lo m√°s pr√≥xima posible de ellos.  \n","  \n","  * Para seleccionar la curva que mejor se ajusta a la nube de puntos, se usa el **m√©todo de los M√≠nimos Cuadrados**.\n","\n","  * Una de las aplicaciones m√°s importantes que tiene la Regresi√≥n es la de ***predecir***. Es decir, conocido un valor de una de las variables, se querr√° **estimar el valor que presentar√°** la otra variable relacionada con ella.\n","\n","2. **Teor√≠a de Correlaci√≥n**: \n","\n","  * Estudia el grado de dependencia entre las variables. En esta ocasi√≥n, el objetivo es medir **el grado de ajuste existente** entre la funci√≥n te√≥rica (funci√≥n ajustada) y la nube de puntos.\n","\n","  * Cuando la relaci√≥n funcional que liga las variables $X$ e $Y$ es una recta, entonces la regresi√≥n y correlaci√≥n reciben el nombre de ***Regresi√≥n Lineal*** y ***Correlaci√≥n Lineal***, respectivamente. \n","  \n","  * Una de las medidas m√°s importantes de la Correlaci√≥n Lineal es el ***Coeficiente de Correlaci√≥n Lineal de Pearson.***\n","\n","\n","La parte de estad√≠stica inferencial (de momento no profundizaremos en ella en este m√≥dulo) trata de analizar si este tipo de relaci√≥n es extrapolable a la poblaci√≥n. Por ahora, s√≥lo se analizar√° la relaci√≥n entre dos variables."]},{"cell_type":"markdown","metadata":{"id":"AhVjQVR_ySKI"},"source":["## 4.1.  L√≠nea general de Regresi√≥n\n","\n","Dentro del estudio de las variables estad√≠sticas bidimensionales, vamos a abordar el an√°lisis de la existencia de **relaciones o dependencias entre dos variables** $X$ e $Y$ que forman parte de la variable bidimensional.\n","\n","B√°sicamente, la relaci√≥n entre esas dos variables **podr√° ser de dos tipos:**\n","\n","* Relaci√≥n **funcional:** cuando exista una funci√≥n matem√°tica exacta que ligue ambas variables. Un ejemplo ser√≠a el radio y el √°rea de un c√≠rculo.\n","\n","* Relaci√≥n **aleatoria:** cuando, aunque no exista entre las variables una relaci√≥n exacta, podemos observar una cierta tendencia entre los comportamientos de ambas. Un ejemplo podr√≠a ser el peso y la altura de un individuo.\n","\n","<br>\n","\n","<font color='Blue'><b> Regresi√≥n o Ajuste </b></font>\n","\n","El primer paso para el estudio de la relaci√≥n entre las variables, consiste en la construcci√≥n y observaci√≥n de un diagrama de dispersi√≥n. Por tanto, la regresi√≥n consiste en ajustar una funci√≥n a la nube de puntos representada en el diagrama.\n","\n","La funci√≥n permitir√° obtener, al menos de forma aproximada, **una estimaci√≥n del valor** de una de las variables a partir del valor que tome la otra.\n","\n","\n","Por tanto, la observaci√≥n de una variable estad√≠stica bidimensional $(X, Y)$ comporta la representaci√≥n de los puntos obtenidos en una nube o diagrama de dispersi√≥n. **El problema general de regresi√≥n se plantea en el intento de ajustar una funci√≥n de ecuaci√≥n conocida** (recta, par√°bola, exponencial, hip√©rbola, polin√≥mica, etc.) **a la nube de puntos**, con la intenci√≥n de poder obtener una predicci√≥n aproximada de una de las variables a partir de la otra.\n","\n","Naturalmente, que **entre todas las funciones** que se pueden elegir para ajustar a la nube de puntos, **debemos seleccionar la √≥ptima**, esto es, la que mejor encaje sobre los puntos. Para lograr esta optimizaci√≥n se usa el **m√©todo de los m√≠nimos cuadrados.**\n","\n","Dependiendo de la forma que adopte la nube de puntos, en un principio, podremos saber si hay que emplear una recta, una par√°bola, una funci√≥n mixta, etc.\n","\n","Una vez elegida la funci√≥n, estimamos los par√°metros correspondientes de la misma a partir de los datos observados. Por ejemplo, imaginemos que la funci√≥n elegida es una l√≠nea recta. Cuya funci√≥n es de la siguiente forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","      y = \\beta_{0} + \\beta_{1}x + \\varepsilon \n","} $$\n","\n","\n","Donde:\n","\n"," * $\\beta_{0}$: es la **constante** del modelo (tambi√©n llamada *intercept*). En muchos libros se opta por representarla con la letra $a$ para simplificar la notaci√≥n.\n","\n"," * $\\beta_{1}$: es la **pendiente** (inclinaci√≥n o tangente) de la recta de regresi√≥n. Este coeficiente indica el incremento de unidades de la variable $Y$ que se produce por cada incremento <u>en una unidad</u> de la variable $X$. Al igual que antes, se representa tambi√©n por la letra $b$.\n","\n"," *$ \\varepsilon $: es el **error** (o *residuo*). Representa la diferencia entre el valor real de $y_{i}$ en una nube de puntos y el valor estimado que proporcionar√≠a la ecuaci√≥n de la recta. En ocasiones, se sustituye la notaci√≥n por la letra $e$.\n","\n","Su representaci√≥n gr√°fica es:\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","Nube de puntos y recta de regresi√≥n lineal\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/d/de/Dispersion-con-regresion.png' width=\"400\" height=\"300\" />\n","<figcaption>Imagen13. Recta de regresi√≥n lineal</figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.es.wikibooks.org](https://es.wikibooks.org/wiki/Archivo:Dispersion-con-regresion.png)\n","\n","\n","\n","Los objetivos para la estimaci√≥n o predicci√≥n son, primero, determinar los *coeficientes* ($\\beta_{0}$ , $\\beta_{1}$) y, despu√©s, comprobar si efectivamente el ajuste era el id√≥neo o no, analizando el *error* o residuo. \n","\n","Normalmente se diferencian **dos tipos de rectas de regresi√≥n** o funciones, que son:\n"," \n","* ***Recta de Regresi√≥n Y sobre X*.** A partir de los valores de $x$ se pueden estimar los valores de $y$. La funci√≥n es del tipo $y = f(x)$.\n","\n","* ***Recta de Regresi√≥n X sobre Y*.** A partir de los valores de $y$ se pueden estimar los valores de $x$. La funci√≥n es del tipo $x = f(y)$."]},{"cell_type":"markdown","metadata":{"id":"X3gy2dmxDalY"},"source":["<font color='Blue'><b> M√©todo de M√≠nimos Cuadrados </b></font>\n","\n","Las observaciones que pasan por la recta, cuya distancia es cero, son un ajuste perfecto. Obviamente, no todas las observaciones presentan un *ajuste perfecto* y se trata de que la distancia entre lo predicho y lo real sea lo menor posible. Se expresa como **SCE** (_S_uma _C_uadrado de los _E_rrores) o como $S(\\beta_{0},\\beta_{1})$.\n","\n","De forma gr√°fica, se pueden analizar las distancias o errores cometidos:\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Regresi%C3%B3n_lineal_direcci%C3%B3n.png/800px-Regresi%C3%B3n_lineal_direcci%C3%B3n.png' width=\"650\" height=\"200\" />\n","<figcaption>Imagen14. Tipos de distancias entre lo real y lo predicho </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.wikimedia.org](https://es.m.wikipedia.org/wiki/Archivo:Regresi%C3%B3n_lineal_direcci%C3%B3n.png)\n","\n","<br>\n","\n","El criterio de M√≠nimos Cuadrados considera que la funci√≥n que mejor se ajusta a los datos es aquella funci√≥n que <u>minimiza la media de los cuadrados de los residuos o errores.</u> Por tanto, su objetivo es la b√∫squeda de minimizar la distancia entre lo que ha ocurrido (valor real) y lo predicho (valor extra√≠do de la recta).\n","\n","El m√©todo de m√≠nimos cuadrados busca minimizar la siguiente expresi√≥n:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  SCE = \\sum_{i=1}^{k}\\sum_{j=1}^{p}f_{ij}\\varepsilon_{ij}^2\n","   = \\sum_{i=1}^{k}\\sum_{j=1}^{p}f_{ij}(y_{j} - (\\beta_{0}+\\beta_{1}x_{i})  )^2} \n","$$\n","\n","La condici√≥n necesaria para la existencia de m√≠nimo es que las primeras derivadas parciales respecto a cada uno de los par√°metros se anulen, es decir que tomen el valor cero. As√≠:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\frac{\\partial S(\\beta_{0},\\beta_{1})}{\\partial\\beta_{0}} \n"," = 2 \\sum_{i=1}^{k}\\sum_{j=1}^{p}f_{ij}(y_{j} - \\beta_{0}-\\beta_{1}x_{i}  )(-1) =0 \\\\} \n"," \\bbox[5px,border: 2px solid blue]{ \n"," \\frac{\\partial S(\\beta_{1},\\beta_{1})}{\\partial\\beta_{0}} \n"," = 2 \\sum_{i=1}^{k}\\sum_{j=1}^{p}f_{ij}(y_{j} - \\beta_{0}-\\beta_{1}x_{i}  )(-x_{i}) =0} \n","$$\n","\n","Estas ecuaciones se llaman ***Ecuaciones Normales*** y a partir de este sistema de ecuaciones se obtienen los par√°metros $\\beta_{0}$ y $\\beta_{1}$, donde:\n","\n","$$ \\beta_{1} = \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } \n"," \\quad \\text{y} \\quad\n"," \\beta_{0} =  \\widehat{y} - \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } \\widehat{x}\n","$$ \n","\n","<br>\n","<p> <mark>PARA SABER M√ÅS</mark> </p>\n","<hr>\n","\n","\n","Te recomendamos la lectura de los siguientes documentos para profundizar en este m√©todo:\n","\n","* [M√©todo de M√≠nimos Cuadrados - paper1 (pdf)](https://github.com/md-lorente/documentation/blob/master/Metodo%20de%20Minimos%20Cuadrados%20-%20paper1.pdf)\n","\n","* [M√©todo de M√≠nimos Cuadrados - paper2 (pdf)](https://github.com/md-lorente/documentation/blob/master/Metodo%20de%20Minimos%20Cuadrados%20-%20paper2.pdf)\n","\n","* [Demostraci√≥n matem√°tica del M√©todo de M√≠nimos Cuadrados](https://github.com/md-lorente/documentation/blob/master/Demostracion_Minimos_Cuadrados.pdf)"]},{"cell_type":"markdown","metadata":{"id":"WV7hPh723_HU"},"source":["### 4.1.1. Recta de Regresi√≥n Y sobre X \n","\n","Para conocer, de entre todas las rectas, aquella que mejor se ajusta a la nube de puntos de la distribuci√≥n bidimensional, se aplica el procedimiento de ***M√≠nimos Cuadrados***.\n","\n","Si suponemos que la funci√≥n que expresa el comportamiento de Y en relaci√≥n con X, tiene la expresi√≥n de **la ecuaci√≥n general** siguiente:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","       y = \\beta_{0} + \\beta_{1}x\n","} $$\n","\n","<br>\n","\n","Esta ser√≠a la *recta te√≥rica* general del modelo.\n","\n","El problema es que la distribuci√≥n de valores no se va a ajustar nunca, de manera perfecta, a ninguna recta as√≠ que, cuando vayamos a calcular un valor de $Y$ determinado $y_{i}$ a partir de un valor de $x_{i}$ perteneciente a $X$, habr√° una **diferencia** (o distancia) entre el valor real de $y_{i}$  y el que se obtendr√≠a directamente de la f√≥rmula de la recta. Esa diferencia se traduce en la expresi√≥n matem√°tica en $\\varepsilon$ que recoge el error o residuo.\n","\n","Por tanto la expresi√≥n quedar√° de la forma vista anteriormente:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y =\\beta_{0} + \\beta_{1}x + \\varepsilon }  $$ \n","\n","Aunque parezca una f√≥rmula similar a la anterior, ha sufrido un cambio importante, ahora tiene presentes dos componentes bien diferenciados:\n","\n","* Un componente **determinista**: $\\beta_{0}$ y $\\beta_{1}$ (los coeficientes).\n","* Un componente **estoc√°stico**: $\\varepsilon$ (el error en la estimaci√≥n).\n","\n","\n","<!-- script html for \"Recuerda\" -->\n","<!-- espaciado salto <br> espaciado de linea &nbsp; -->\n","<br>\n","<p> <mark> PIENSA UN MINUTO </mark> </p>\n","<hr>\n","<p>\n","<br>\n","<center><b>\n","\n","Entonces‚Ä¶ ¬ø puedo predecir, asumiendo un error, lo que valdr√° y a partir de x si conozco los coeficientes de la ecuaci√≥n ?\n","\n","</center></b>\n","<br>\n","\n","Para determinar el valor de los coeficientes, se aplica el _M√©todo de M√≠nimos Cuadrados_ donde, como se ha visto anteriormente, se obtiene que:\n","\n","* El segundo coeficiente o el valor de la *pendiente* se determina como la *relaci√≥n* entre la *covarianza* y la *varianza*, esto es:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\beta_{1} = \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } }  $$ \n","\n","\n","* Con el valor del segundo coeficiente y despejando el primer coeficiente de la ecuaci√≥n, se obtiene el valor de la *constante*:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\beta_{0} =  \\widehat{y} - \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } \\widehat{x} } $$ \n","\n","Por √∫ltimo, de la ecuaci√≥n vista quedar√≠a determinar el valor de $\\varepsilon $. Es decir, el *error* que representa la diferencia entre el valor real de $y_{i}$ en la nube de puntos y el valor estimado que resulta de la ecuaci√≥n de la recta. Su expresi√≥n matem√°tica es:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\varepsilon_{i} =  y_{i} - \\widehat{y}_{i} } $$ \n","\n","Siendo $\\widehat{y}$ la manera de expresar la estimaci√≥n o el valor estimado.\n","\n","\n","Por tanto, aplicando todo lo visto hasta el momento, la **Recta de Regresi√≥n Y sobre X** tiene la siguiente ecuaci√≥n general:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   y - \\widehat{y} = \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } (x - \\widehat{x}) \n","} \\\\ \\\\ $$ \n","\n","Donde $ \\beta_{1}$ representa el **Coeficiente de Regresi√≥n de $Y$ sobre $X$** que representa la variaci√≥n de $Y$ si $X$ aumenta en una unidad.\n","\n","<br>\n","<p> <mark>RECUERDA</mark> </p>\n","<hr>\n","\n","\n","En conclusi√≥n, una de las aplicaciones de la recta de regresi√≥n Y sobre X es **predecir el valor de Y conocido el valor de X.**"]},{"cell_type":"markdown","metadata":{"id":"wzFKXg5UajN8"},"source":["### 4.1.2. Recta de Regresi√≥n X sobre Y\n","\n","En ocasiones, nuestro **objetivo es predecir el valor de $X$ conocido el valor de $Y$** entonces, ser√° necesario utilizar la recta de regresi√≥n $X$ sobre $Y$.\n","\n","Para ello, procederemos de forma an√°loga al apartado anterior, repitiendo el *m√©todo de M√≠nimos Cuadrados* sobre la media de los cuadrados de los residuos, resultando la siguiente expresi√≥n de la recta de regresi√≥n $X$ sobre $Y$:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   x - \\widehat{x} = \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } (y - \\widehat{y}) \n","} $$ \n","\n","Donde el **Coeficiente de Regresi√≥n de $X$ sobre $Y$** se denota por $\\beta_{1}$ con la misma f√≥rmula vista anteriormente, aunque, en este caso, representa la variaci√≥n de $X$ si $Y$ aumenta en una unidad.\n","\n","Sabemos que el **signo del valor de la covarianza** indica el sentido de la relaci√≥n entre las variables y rec√≠procamente. Pero el valor de la covarianza depende de las unidades en que vengan expresadas las variables. Recordemos que la covarianza de $X$ e $Y$ **puede tener signo positivo o negativo**, de hecho tiene el mismo **signo que la pendiente de la recta** ajustada. Por tanto:\n","\n","* Si la covarianza es positiva, $X$ e $Y$ presentan una asociaci√≥n positiva (cuando crece $X$, crece $Y$ y cuando decrece $X$, decrece $Y$).\n","\n","* Si  la  covarianza es negativa, $X$ e $Y$ presentan una asociaci√≥n negativa (cuando crece una decrece la otra).\n","\n","* Si las variables son independientes, la covarianza es nula aunque el rec√≠proco no es cierto.\n","\n","Por tanto, es necesario definir **un coeficiente que mida el grado de variaci√≥n conjunta entre las variables** y al mismo tiempo no est√© afectado por las unidades de la medida. Una forma de obtener ese dato es a trav√©s de la **correlaci√≥n.**"]},{"cell_type":"markdown","metadata":{"id":"L9AaPrzWdg78"},"source":["## 4.2. Correlaci√≥n\n","\n","As√≠ como la regresi√≥n estudia la posible predicci√≥n de los valores de una variable a partir de la otra, la correlaci√≥n estudia el **tipo de dependencia que existe entre ambas variables**, intentando cuantificarla mediante el c√°lculo de los coeficientes de correlaci√≥n.\n","\n","A continuaci√≥n, estudiaremos los **coeficientes de determinaci√≥n y correlaci√≥n lineal.**"]},{"cell_type":"markdown","metadata":{"id":"hD0-YpJseUp5"},"source":["### 4.2.1. Coeficiente de correlaci√≥n lineal de Pearson\n","\n","**El coeficiente de correlaci√≥n lineal** es un n√∫mero abstracto que determina el grado de ajuste entre una nube de puntos y una recta de regresi√≥n. Es decir, un coeficiente que **mide el grado de variaci√≥n conjunta** entre las variables y no est√° afectado por las unidades de medida. Se representa por $r$ o por su notaci√≥n griega $\\rho$.\n","\n","La forma de obtener esta medida es **dividir la covarianza por el producto de las desviaciones t√≠picas de cada variable**, dando como resultado un **coeficiente adimensional**. \n","\n","Su f√≥rmula matem√°tica es:\n","\n","$$ \\\\ \\bbox[5px,border: 2px solid blue]{ \n","   r = \\frac{\\sigma_{xy}} { \\sigma_{x} \\sigma_{y}}  \n","} \\\\ $$ \n","\n","Este coeficiente determina si existe relaci√≥n lineal entre dos variables, y toma valores entre -1 y 1, esto es:\n","\n","$$ \\\\ \\bbox[5px,border: 2px solid blue]{ \n","  -1 \\leq r \\leq 1  \n","} $$ \n","\n","<br>\n","\n","<u><b> Interpretaci√≥n del valor obtenido del coeficiente: </u></b>\n","\n","El resultado obtenido del coeficiente de correlaci√≥n lineal de Pearson se debe interpretar de la siguiente manera:\n","\n","* Si $-1 < r < 0$ implica que existe **dependencia aleatoria inversa**. La expresi√≥n se puede resumir en: $ r < 0$.\n","\n","* Si $r = 0$  o $r‚âà0$, puede afirmarse que <u><b>no existe relaci√≥n lineal</u></b> entre las variables. Entonces se dice que las variables son incorreladas.\n","\n","* Si $0 < r < 1$ implica que existe **dependencia aleatoria directa**. La expresi√≥n se puede resumir en: $ r > 0$  \n","\n","* Si $|r|$ est√° pr√≥ximo a 1 se dice que <u><b>existe una relaci√≥n lineal</u></b> muy fuerte entre las variables.\n","\n","* Si $ r = ¬±1 $ entonces las observaciones de ambas variables est√°n perfectamente alineadas. Se puede afirmar que hay **dependencia funcional** lineal entre las variables. El signo de $r$ que coincida con el de $\\sigma_{xy}$ mostrar√° el crecimiento o decrecimiento de la recta.\n","\n","\n","<br>\n","\n","<u><b> Propiedades del coeficiente de correlaci√≥n lineal de Pearson: </u></b> \n","\n","* Es un coeficiente adimensional (carece de unidades de medida).\n","\n","* Es invariante frente a los cambios de origen y escala de las variables. \n","\n","* Utilizando el coeficiente de correlaci√≥n lineal, las Rectas de Regresi√≥n $Y$ sobre $X$ y $X$ sobre $Y$ tambi√©n se pueden expresar, respectivamente, de la siguiente forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y - \\widehat{y} = r \\frac{\\sigma_{y}} { \\sigma_{x} } (x - \\widehat{x})  \\quad \\text{;} \\quad \n","   x - \\widehat{x} = r \\frac{\\sigma_{x}} { \\sigma_{y} } (y - \\widehat{y}) } \n","$$\n","\n","<br>\n","\n","<u><b> Interpretaci√≥n gr√°fica </u></b> \n","\n","La representaci√≥n de la recta de regresi√≥n y el valor del coeficiente de correlaci√≥n lineal de Pearson en una gr√°fica tiene las siguientes opciones, que variar√°n en funci√≥n del valor obtenido de $r$. Estas son:\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/8/83/Pearson_Correlation_Coefficient_and_associated_scatterplots.png' width=\"600\" height=\"350\" />\n","<figcaption>Imagen15. Coeficiente de Correlaci√≥n Lineal de Pearson </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.en.wikipedia.org](https://en.wikipedia.org/wiki/File:Pearson_Correlation_Coefficient_and_associated_scatterplots.png)\n","\n","\n","<br>\n","\n","<font color='Blue'><b> Posici√≥n relativa de las rectas de regresi√≥n </b></font>\n","\n","Si se eleva el *coeficiente de correlaci√≥n lineal* al cuadrado se obtiene la expresi√≥n matem√°tica siguiente:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  r^2 = \\frac{\\sigma_{xy}^2} { \\sigma_{x}^2 \\sigma_{y}^2}  \n","=  \\frac{\\sigma_{xy}} { \\sigma_{x}^2 }  \\cdot \\frac{\\sigma_{xy}} { \\sigma_{y}^2 } = \\beta_{yx} \\cdot \\beta_{xy} \n","\\quad \\Longrightarrow \\quad r = \\sqrt{ \\beta_{yx} \\cdot \\beta_{xy} }} \n","$$ \n","\n","donde el signo que se elige en la ra√≠z es el signo de la covarianza.\n","\n","Si se tiene en cuenta que las expresiones de las rectas de regresi√≥n de $Y$ sobre $X$ y $X$ sobre $Y$ indican que pasan por el punto $(x,y)$, entonces s√≥lo pueden **presentar dos posiciones en el plano**:\n","\n","* Se cortan s√≥lo en ese punto $(x,y)$.\n","\n","* O bien presenta coincidencia. Esto es, dichas rectas coinciden cuando, adem√°s de tener el punto $(x,y)$ en com√∫n, tienen la misma pendiente. Por tanto, se puede afirmar que:\n","\n","  * Si $r^2 = 1 \\Longrightarrow $ Las rectas de regresi√≥n coinciden. Existe dependencia funcional.\n","\n","  * Si $r^2 \\neq 1 \\Longrightarrow $ Las rectas de regresi√≥n se cortan en el punto $(x, y)$."]},{"cell_type":"markdown","metadata":{"id":"72C-u_fTHsTK"},"source":["### 4.2.2. Bondad de ajuste\n","\n","Por bondad del ajuste hay que entender **el grado de acoplamiento** que existe entre el valor real (de los datos originales) y el valor estimado (de la funci√≥n) que se obtiene de la regresi√≥n. \n","\n","**La bondad de ajuste indica si el modelo es consistente o no**. Las medidas de bondad analizan la discrepancia entre los valores del pasado observados y los valores del futuro representados en el modelo de estudio. Obviamente, **cuanto mejor sea el ajuste, m√°s √∫til y consistente ser√° el modelo finalmente elegido.**\n","\n","Es decir, despu√©s de construir una recta de regresi√≥n, es necesario saber hasta qu√© grado es posible sustituir dicha funci√≥n estimada por los datos de la que se obtuvo, y saber el grado de dependencia entre las variables. \n","\n","Para calcular la bondad de ajuste hay varios m√©todos. Vamos a ver los m√°s importantes:\n","\n"," * Varianza Residual.\n"," * Coeficiente de Determinaci√≥n.\n","\n","<br>\n","\n","<font color='Blue'><b> Varianza Residual </b></font>\n","\n","**La _Varianza Residual_ es la media de los cuadrados de los residuos** o errores que se cometen cuando se ajusta una curva a la nube de puntos utilizando el m√©todo de m√≠nimos cuadrados. Por tanto, **mide la precisi√≥n** del ajuste de la recta de regresi√≥n. Tambi√©n se llama _Varianza no explicada._\n","\n","La ra√≠z cuadrada de la varianza residual es conocida como el **error t√≠pico.**\n","\n","La varianza residual se halla con la suma de cuadrados de las diferencias entre los valores de la variable dependiente observados y estimados por la recta, dividiendo el resultado final por el tama√±o menos dos. Por tanto, su f√≥rmula matem√°tica tiene la siguiente forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\sigma_{R}^2 = \\frac{1}{n-2} \\sum_{i=1}^n e_{i}^2\n","} $$ \n","\n","Donde $ e_{i} = y_{i} - \\widehat{y}_{i} $ son los residuos del modelo.\n","\n","Si fuera la recta de regresi√≥n de $X$ sobre $Y$ habr√≠a que cambiar la f√≥rmula quedando:\n","\n"," $$ \\bbox[5px,border: 2px solid blue]{ \n","   e_{i} = x_{i} - \\widehat{x}_{i} } $$\n","\n","\n","Se divide por $n-2$ (y no por $n$), porque **los residuos son independientes**, ya que las ecuaciones normales inducen dos restricciones sobre ellos, que son:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\sum_{i=1}^n e_{i} = 0 \\quad \\text{y} \\quad \\sum_{i=1}^n e_{i}x_{i} = 0 }$$ \n","\n","<br>\n","<p> <mark>SAB√çAS QUE...</mark> </p>\n","<hr>\n","\n","En la pr√°ctica, existe otra forma para calcular la varianza residual, sin utilizar expl√≠citamente los residuos:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\sigma_{R}^2 = \\frac{n (\\sigma_{y}^2 - \\widehat{\\beta_{1}^2} \\sigma_{x}^2 ) }{n-2} \n","}$$\n","\n","La _Varianza Residual_ se utiliza como medida de la bondad del ajuste. Por tanto, **cuanto menor sea la Varianza Residual, menores ser√°n los residuos** y por ende, mejor ser√° el ajuste de la curva a la nube de puntos. \n","\n","<br>\n","<p> <mark>RECUERDA</mark> </p>\n","<hr>\n","\n","**Este c√°lculo presenta un inconveniente**, no s√© sabe si dicha varianza es suficientemente peque√±a o suficientemente grande para considerar que el ajuste realizado es un buen o un mal ajuste. Esta desventaja se puede solucionar apoy√°ndose en el _Coeficiente de Determinaci√≥n._\n","\n","\n","<!-- script html for \"Recuerda\" -->\n","<!-- espaciado salto <br> espaciado de linea &nbsp; -->\n","<br>\n","<p> <mark> IMPORTANTE</mark> </p>\n","<hr>\n","<p>\n","\n","Hay que tener las siguientes consideraciones:\n","\n","* La varianza residual ($ \\sigma_{R}^2 $) es una **varianza** y, por tanto, su valor debe ser **siempre positivo.** Si al calcularlo aparecen valores negativos, ser√° debido a errores de redondeo. En caso de que esto ocurriera, debemos tomar una **mayor precisi√≥n decimal** en las estimaciones de $\\sigma_{y}^2$; $\\sigma_{x}^2$ y $\\widehat{\\beta_{1}^2}$.\n","\n","* La recta de regresi√≥n y la desviaci√≥n t√≠pica residual juegan el mismo papel que la media y la desviaci√≥n t√≠pica en una distribuci√≥n de datos. Por tanto, **la recta de regresi√≥n indica el valor medio de $y$ para cada valor de $x$**;</u> mientras que, **la desviaci√≥n t√≠pica mide la desviaci√≥n promedio de las observaciones alrededor de la recta**.\n"]},{"cell_type":"markdown","metadata":{"id":"10fTvwNVRCjn"},"source":["<font color='Blue'><b> Coeficiente de Determinaci√≥n </b></font>\n","\n","El Coeficiente de Determinaci√≥n es una **medida de la capacidad que la ecuaci√≥n de regresi√≥n** tiene para ajustarse a los datos, es decir, para obtener predicciones buenas (en el sentido de que sean lo menos err√≥neas posible).\n","\n","El valor del coeficiente nos ayudar√° a tomar una decisi√≥n sobre si es aceptable o no el modelo de regresi√≥n y se representa por $R^2$.\n","\n","Hay muchas definiciones del Coeficiente de Determinaci√≥n tambi√©n llamado **Raz√≥n de Correlaci√≥n**.\n","\n","Se puede definir como **el cuadrado del coeficiente de correlaci√≥n de Pearson,**. Esto es cierto para la regresi√≥n lineal simple. \n","\n","Otra definici√≥n para el Coeficiente de Determinaci√≥n es la **proporci√≥n de la varianza total de la variable explicada por la regresi√≥n.**\n","\n","<br>\n","<p> <mark>RESUMEN</mark> </p>\n","<hr>\n","\n","**Es un importante estad√≠stico en el estudio de la regresi√≥n**.\n","\n","El motivo principal es que se trata de una medida del grado de relaci√≥n existente entre la variable dependiente respecto a la variable o variables independientes.\n","\n","Su f√≥rmula matem√°tica es:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   R^2 = \\frac{\\sum_{i=1}^n (\\widehat{y} - \\bar{y})^2 }{\\sum_{i=1}^n ( y_{i} - \\bar{y})^2} \n","} $$ \n","\n","Este coeficiente determina el grado de relaci√≥n lineal entre dos variables, y toma valores entre 0 y 1. Esto se traduce en que cumple la siguiente regla:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  0 \\leq R^2 \\leq 1  \n","} $$ \n","\n","<br>\n","\n","<u><b> Interpretaci√≥n del Coeficiente obtenido: </u></b>\n","\n","El resultado obtenido del coeficiente de Determinaci√≥n se debe interpretar de la siguiente manera:\n","\n","* **Si $R^2 = 0$ √≥ $R^2 ‚âà 0$ implica que es un mal ajuste**. Cuando el coeficiente vale exactamente 0 implica que no explica nada la recta de regresi√≥n, y por tanto, es el peor ajuste que puede hacerse por el procedimiento de m√≠nimos cuadrados. Es decir, tiene **nula capacidad predictiva cuando es igual a 0**.\n","\n","* **Si $R^2 = 1$ √≥ $R^2 ‚âà 1$ implica que es un buen ajuste.** Cuando el coeficiente vale **exactamente 1 implica que todos los residuos son nulos**.\n","Cuando todos los puntos de la nube de puntos est√°n sobre la curva, el ajuste es perfecto. **Si $R^2$ toma el valor uno significa que el ajuste es perfecto entre la nube de puntos y la ecuaci√≥n estimada**.\n","\n","<br>\n","\n","<u><b> Relaci√≥n entre el coeficiente de determinaci√≥n y el coeficiente de correlaci√≥n lineal de Pearson </u></b>\n","\n","El coeficiente de determinaci√≥n se puede expresar y desarrollar de la siguiente forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   R^2 = 1 - \\frac{\\sigma_{R}^2}{\\sigma_{y}^2} \n","   = 1 - \\frac{\\sigma_{y}^2 (1-r^2)}{\\sigma_{y}^2} = r^2 } \n","$$ \n","\n","Y se obtendr√≠a el mismo resultado para su hom√≥logo con la recta de regresi√≥n de $X$ sobre $Y$. Esto es:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   R^2 = 1 - \\frac{\\sigma_{R}^2}{\\sigma_{x}^2} \n","   = 1 - \\frac{\\sigma_{x}^2 (1-r^2)}{\\sigma_{x}^2} = r^2 } \n","$$ \n","\n","Por lo explicado hasta el momento, el coeficiente de correlaci√≥n lineal de Pearson al cuadrado, $r^2$, se utiliza como medida de la bondad del ajuste de la recta de m√≠nimos cuadrados.\n","\n","<br>\n","<p> <mark>RECUERDA</mark> </p>\n","<hr>\n","\n","Una regla importante a recordar es la que se muestra a continuaci√≥n: \n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\quad  r^2 = R^2 \\quad \\Longrightarrow \\quad r = \\pm \\sqrt{R^2} } $$\n","\n","<br>\n","\n","<u><b> La desventaja del Coeficiente de Determinaci√≥n </u></b>\n","\n","El problema del *coeficiente de determinaci√≥n*, y raz√≥n por el cual surge el *coeficiente de determinaci√≥n ajustado*, radica en que **no penaliza la inclusi√≥n de variables explicativas no significativas**. Es decir, si al modelo le a√±adimos cinco variables explicativas que guardan poca relaci√≥n con la variable a predecir, el $R^2$ aumentar√°. Es por ello que algunos expertos se oponen al uso del $R^2$ como medida representativa de la bondad del ajuste real.\n","\n","\n","<br>\n","\n","<font color='Blue'><b> Coeficiente de Determinaci√≥n Ajustado </b></font>\n","\n","El coeficiente de determinaci√≥n ajustado o corregido es una medida que define el porcentaje explicado por la varianza de la regresi√≥n en relaci√≥n con la varianza de la variable explicada. Es decir, lo mismo que el $R^2$, pero con la diferencia de que el coeficiente de determinaci√≥n ajustado penaliza la inclusi√≥n de variables.\n","\n","C√≥mo hemos dicho anteriormente, el coeficiente de determinaci√≥n de un modelo aumenta aunque las variables que incluyamos no sean relevantes. Ya que esto supone un problema. Para intentar solventarlo el *R-cuadrado ajustado* se utiliza la siguiente expresi√≥n:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\bar{R}^2 = 1 - \\frac{N-1}{N-k-1} (1-R^2)\n","} $$ \n","\n","Donde:\n","* $N$ es el tama√±o de la muestra.\n","\n","* $k$ es el n√∫mero de variables explicativas.\n","\n","* $R^2$ es el coeficiente de determinaci√≥n.\n","\n","\n","Por deducci√≥n matem√°tica, a valores m√°s altos de $k$, m√°s alejado estar√° el _R-cuadrado ajustado_ del _R-cuadrado normal_. Al rev√©s, a valores m√°s bajos de $k$, m√°s cerca estar√° de 1 la fracci√≥n central y, por tanto, m√°s parecidos ser√°n el *R-cuadrado ajustado* y el *R-cuadrado normal*.\n","\n","Recordando que $k$ es el n√∫mero de variables explicativas, deducimos que √©ste no puede ser cero ya que si fuese cero, no existir√≠a modelo.\n","\n","Como m√≠nimo tendremos que explicar una variable en funci√≥n de otra variable. Dado que $k$ debe ser como m√≠nimo 1, el *R-cuadrado ajustado* y el *R-cuadrado normal* no pueden tener el mismo valor. \n","\n","En resumen, el *R-cuadrado ajustado* ser√° siempre inferior al *R-cuadrado normal*, cumpli√©ndose siempre la siguiente condici√≥n:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\bar{R}^2 < R^2 } $$"]},{"cell_type":"markdown","metadata":{"id":"Nyv04H3EufJl"},"source":["<!-- script html for \"Recuerda\" -->\n","<!-- espaciado salto <br> espaciado de linea &nbsp; -->\n","<br>\n","<p> <mark>RECUERDA</mark> </p>\n","<hr>\n","<p>\n","\n","Con las **variables bidimensionales** se trata de predecir una variable a trav√©s de dos o m√°s variables. Es decir:\n","\n","* El **objetivo** es determinar si existe **relaci√≥n entre dos variables**.\n","\n","* La **teor√≠a de regresi√≥n** trata de predecir los valores de una variable fijando los valores de la otra.\n","\n","* La **teor√≠a de correlaci√≥n** trata de predecir los valores midiendo la dependencia entre las variables.\n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","Ten en cuenta los siguientes puntos de la **Regresi√≥n y la Correlaci√≥n**:\n","\n","* El m√©todo de los m√≠nimos cuadrados **mide la distancia m√°s corta entre dos puntos** (real y estimado).\n","\n","* **Correlaci√≥n no siempre significa causa**:\n","\n","  * Dos variables var√≠an de forma simult√°nea.\n","\n","  * Consecuencia de terceras variables. Cuidado con terceras variables que afectan la relaci√≥n entre las dos variables que se est√©n analizando.\n","\n","  * Para que una sea causa y efecto:\n","   * Debe haber relaci√≥n.\n","   * Una debe suceder antes que la otra.\n","   * No deben existir terceras variables.\n"," \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"L2M-A7PYyLov"},"source":["<!-- script html for \"Recuerda\" -->\n","<!-- espaciado salto <br> espaciado de linea &nbsp; -->\n","<br>\n","<p> <mark> IMPORTANTE </mark> </p>\n","<hr>\n","<p>\n","\n","Recuerda los siguientes puntos:\n","\n","* Las interpretaciones de las variables significativas son las mismas tanto para modelos con alto $R^2$ como con bajo $R^2$.\n","\n","* Los coeficientes estiman las tendencias mientras que $R^2$ representa la dispersi√≥n alrededor de la l√≠nea de regresi√≥n.\n","\n","* Los valores de $R^2$ bajos son problem√°ticos cuando se necesitan predicciones precisas.\n","\n","* La regresi√≥n se entiende representativa cuando $R^2 \\geq 0.75$. Los valores intermedios nos indican mayor o menor representatividad. \n","\n","* Si se tienen predictores significativos pero una bajo valor $R^2$, se puede hacer lo siguiente:  \n","\n","  * Una de las opciones m√°s habituales es a√±adir variables al modelo. Si bien es cierto que los predictores adicionales puedan incrementar la potencia explicativa verdadera del modelo, no siempre resolver√° el problema. \n","\n","  * Ten en cuenta que en algunos casos no se podr√°n a√±adir porque la naturaleza del estudio o de los datos presenta una alta variabilidad.\n"]},{"cell_type":"markdown","metadata":{"id":"NkBW7AsF0H8v"},"source":["## 4.3. Regresi√≥n No-Lineal\n","\n","En esta secci√≥n estudiaremos c√≥mo realizar el ajuste de las funciones no-lineales a los puntos de la nube de puntos.\n","\n","Veremos las funciones m√°s usadas y representativas como son la regresi√≥n exponencial, la regresi√≥n lineal m√∫ltiple, etc.\n","\n","<br>\n","\n","<font color='Blue'><b> Regresi√≥n exponencial </b></font>\n","\n","La regresi√≥n exponencial o funci√≥n exponencial es una regresi√≥n no-lineal, aunque aplicando las reglas de los logaritmos, se puede transformar en lineal. \n","\n","Es decir, si realizamos los siguientes pasos lograremos cambiarla a _lineal_:\n","\n","1. Partimos de la siguiente funci√≥n exponencial:\n","\n","$$ y = (\\beta_{0} \\cdot \\beta_{1})^x   \n"," \\quad \\text{con} \\quad \\beta_{0}, \\beta_{1} \\in \\mathbb R\n","$$ \n","\n","2. Tomamos los logaritmos neperianos en toda la expresi√≥n:\n","\n","$$ \\ln y = \\ln \\beta_{0} + x \\cdot \\ln \\beta_{1}    $$ \n","\n","3. Aplicamos la siguiente transformaci√≥n o cambio de variable:\n","\n","$$  y' = \\ln y  \\quad  ;  \\quad  \\beta_{0}' = \\ln \\beta_{0} \n","  \\quad  ;  \\quad  \\beta_{1}' = \\ln \\beta_{1} $$ \n","\n","4. Y obtenemos la siguiente expresi√≥n al sustituir:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y' = \\beta_{0}' + \\beta_{1}'x   \n","} $$ \n","\n","Por lo que, al transformarla en lineal, simplemente debemos hallar los coeficientes e ir hacia atr√°s con los valores obtenidos. \n","\n","El √∫ltimo paso, pero no por ello menos importante, consiste en a√±adir el error cometido a la ecuaci√≥n general. Por lo que la expresi√≥n final quedar√≠a de la siguiente forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y' = \\beta_{0}' + \\beta_{1}'x + \\varepsilon\n","}\n","$$\n","\n","<br>\n","\n","<font color='Blue'><b> Regresi√≥n logar√≠tmica </b></font>\n","\n","Este modelo de regresi√≥n es una alternativa cuando el modelo lineal no logra un coeficiente de determinaci√≥n apropiado, o cuando el fen√≥meno de un estudio tiene un comportamiento que puede considerarse potencial o logar√≠tmico.\n","\n","Este modelo tambi√©n es conocido como **potencial, Cobb-Douglas de primer grado o exponencial inverso**.\n","\n","La funci√≥n que define el modelo tiene la forma siguiente:\n","\n","$$ y = \\beta_{0} \\cdot  x^{ \\beta_{1}}\n"," \\quad \\text{con} \\quad \\beta_{0}, \\beta_{1} \\in \\mathbb R\n","$$ \n","\n","En este tipo de funciones, antes de aplicar el m√©todo de m√≠nimos cuadrados, hay que linealizar. Para ello, tomamos logaritmos neperianos o decimales en la ecuaci√≥n anteriormente escrita, por tanto:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\ln y = \\ln \\beta_{0} + \\beta_{1} \\cdot \\ln x   } $$ \n","\n","Al igual que vimos antes, simplemente realizaremos un cambio de variable para luego sustituirlo, siendo el siguiente:\n","\n","$$  y' = \\ln y  \n","  \\quad  ;  \\quad  \\beta_{0}' = \\ln \\beta_{0} \n","  \\quad  ;  \\quad  x' = \\ln x \n","$$ \n","\n","Logrando transformar la funci√≥n potencial en una lineal de la siguiente forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y' = \\beta_{0}' + \\beta_{1}x'   \n","} $$ \n","\n","Al igual que antes, hemos reducido el problema para obtener los coeficientes y sustituir por los valores finales.\n","\n","Debemos a√±adir el error aleatorio cometido a la ecuaci√≥n obtenida, quedando finalmente de la siguiente manera:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y' = \\beta_{0}' + \\beta_{1}x' + \\varepsilon\n","} $$\n","\n","\n","<br>\n","\n","<font color='Blue'><b> Hip√©rbola equil√°tera </b></font>\n","\n","Si la curva que mejor se ajusta a la nube de puntos es de tipo hiperb√≥lico, es decir, sigue la siguiente ecuaci√≥n:\n","\n","$$ y = \\beta_{0} + \\frac{\\beta_{1}}{ x}\n"," \\quad \\text{con} \\quad \\beta_{0}, \\beta_{1} \\in \\mathbb R\n","$$ \n","\n","Simplemente, necesitamos una transformaci√≥n para linealizar la expresi√≥n, esto es:\n","\n","$$ \n","\\bbox[5px,border: 2px solid blue]{ z = \\frac{1}{ x}   } $$ \n","\n","Con este sencillo paso, obtenemos la siguiente expresi√≥n al sustituir:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y = \\beta_{0} + \\beta_{1} z   \n","}$$ \n","\n","La ecuaci√≥n de la hip√©rbola equil√°tera se transforma en una recta cuyo ajuste se realiza por m√≠nimos cuadrados, y como √∫ltimo paso, a√±adimos el error aleatorio en la ecuaci√≥n, quedando:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y = \\beta_{0} + \\beta_{1} z   + \\varepsilon\n","}$$"]},{"cell_type":"markdown","metadata":{"id":"GEL8lAI5GTTE"},"source":["<font color='Blue'><b> Regresi√≥n lineal m√∫ltiple </b></font>\n","\n","Veamos, ahora, como la variable $Y$ depende linealmente de m√°s de una variable. El modelo gen√©rico es: \n","\n","$$ y = \\beta_{0} + \\beta_{1}x_{1}  + \\ldots + \\beta_{k}x_{k}\n"," \\quad \\text{con} \\quad \\beta_{0}, \\beta_{1},\\ldots, \\beta_{k} \\in \\mathbb R\n","$$ \n","\n","Los casos particulares de la regresi√≥n lineal m√∫ltiple son:\n","\n","* si $k = 1$ se obtiene el caso particular de la regresi√≥n lineal (vista previamente).\n","\n","* si $k = 2$ se obtiene el caso particular de la regresi√≥n parab√≥lica.\n","\n","* si $k > 2$ entonces estamos ante una regresi√≥n polinomial.\n","\n","Veamos en detalle estas dos √∫ltimas opciones.\n","\n","<br>\n","\n","<font color='Blue'><b> Par√°bola </b></font>\n","\n","Al crear el gr√°fico de dispersi√≥n, observamos que una curva (y no una l√≠nea recta) se ajusta mejor a la nube de puntos; entonces estamos ante un caso de tipo parab√≥lico.\n","\n","Recordemos la funci√≥n parab√≥lica, que es del siguiente tipo:\n","\n","$$ y = \\beta_{0} + \\beta_{1}x  + \\beta_{2}x^2 \n"," \\quad \\text{con} \\quad \\beta_{0}, \\beta_{1}, \\beta_{2} \\in \\mathbb R\n","$$ \n","\n","Donde el objetivo es aplicar el criterio de *M√≠nimos Cuadrados*, esto es, considerar que la funci√≥n que mejor se ajusta a los datos es aquella funci√≥n que minimiza la media de los cuadrados de los residuos. Luego:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  SCE = \\sum_{i=1}^{k}\\sum_{j=1}^{p}f_{ij}\\varepsilon_{ij}^2\n","   = \\sum_{i=1}^{k}\\sum_{j=1}^{p}(y_{j} - (\\beta_{0}+\\beta_{1}x_{i}+\\beta_{2}x_{i}^2)  )^2\n","} $$\n","\n","La condici√≥n necesaria para la existencia de m√≠nimo es que las derivadas parciales respecto a cada uno de los par√°metros sea igual a cero, donde se convierte en un sistema de tres ecuaciones con tres inc√≥gnitas que al resolverlo nos da el valor de los coeficientes de $\\beta_{0}$, $\\beta_{1}$ y $\\beta_{2}$.\n","\n","\n","\n","<br>\n","\n","<font color='Blue'><b> Regresi√≥n Polinomial </b></font>\n","\n","Supongamos que la nube de puntos se ajusta a la siguiente regresi√≥n polin√≥mica:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{1}^2 + \\beta_{3}x_{2} + \\beta_{4}x_{2}^2 + \\beta_{5}x_{1}x_{2} \n","} \\\\ $$ \n","\n","\n","\n","Debemos tener en cuenta la siguiente consideraci√≥n: una ***regresi√≥n multivariable*** tiene varias variables. Si suponemos el caso m√°s sencillo, por ejemplo s√≥lo dos variables ($x_{1}$ y $x_{2}$), su expresi√≥n en regresi√≥n lineal ser√≠a de la forma:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}\n","} $$ \n","\n","Como podemos observar para la _Regresi√≥n Polinomial_, se crean algunas caracter√≠sticas adicionales que no se encuentran en la _Regresi√≥n Lineal._\n","\n","El t√©rmino polinomial convierte un modelo de regresi√≥n lineal en una curva. Teniendo en cuenta que los datos de $X$ son cuadr√°ticos o c√∫bicos pero el coeficiente $\\beta$ no lo es, los podemos tratar como un modelo lineal.\n","\n","Esto hace que sea una forma agradable y sencilla de modelar curvas sin tener que modelar modelos complicados no lineales.\n","\n","Un patr√≥n com√∫n dentro de **Machine Learning** es usar **modelos lineales entrenados en funciones no lineales de los datos**. Este enfoque mantiene el rendimiento generalmente r√°pido de los m√©todos lineales mientras que les permite ajustarse a un rango de datos mucho m√°s amplio.\n","\n","Al considerar los ajustes lineales dentro de un espacio de mayor dimensi√≥n construido con estas funciones b√°sicas, el modelo tiene la flexibilidad de adaptarse a una gama de datos mucho m√°s amplia.\n","\n","<br>\n","\n","<u>**Consideraciones de la Regresi√≥n Polinomial:**</u>\n","\n","* A medida que se aumenta la complejidad de la f√≥rmula, el n√∫mero de caracter√≠sticas tambi√©n aumenta, lo que a veces es dif√≠cil de manejar.\n","\n","* Cambiar el valor de $y$ en un punto del conjunto de entrenamiento puede afectar al ajuste del polinomio para puntos de datos que est√°n muy lejos. \n","\n","  Por lo tanto, para evitar el uso de polinomios de alto grado en todo el conjunto de datos, los podemos sustituir con otras funciones de peque√±o grado diferentes.\n","\n","* Tiene una tendencia a ajustarse dr√°sticamente, incluso es un simple conjunto de datos unidimensional. \n","\n","  En ocasiones, se trata de resolver este problema ajustando a un polinomio de mayor grado para obtener un error menor. Esto **puede resultar en un ajuste excesivo**. Por esa raz√≥n, siempre se deben trazar las relaciones para ver el ajuste y focalizar el objetivo en que la curva se ajuste a la naturaleza del problema.\n","\n","  <br>\n","<p> <mark>RECUERDA</mark> </p>\n","<hr>\n","\n","  Hay que **prestar especial atenci√≥n a la curva hacia los extremos y analizar si las formas y tendencias tienen sentido**. En ocasiones, los polinomios superiores pueden terminar produciendo resultados extra√±os en la extrapolaci√≥n.\n","\n","\n","En conclusi√≥n, la _Regresi√≥n Polinomial_ es muy similar a la _Regresi√≥n Lineal,_ con una ligera desviaci√≥n en la forma en que la que se trata nuestro espacio de caracter√≠sticas."]},{"cell_type":"markdown","metadata":{"id":"HAbrrvPCaFF6"},"source":["## 4.4. Correlaci√≥n entre atributos\n","\n","Los modelos de regresi√≥n vistos s√≥lo podemos aplicarlos cuando las variables estudiadas son cuantitativas.\n","\n","Para estudiar la **relaci√≥n entre atributos, tanto ordinales como nominales**, es necesario recurrir a otro tipo de medidas de relaci√≥n o de asociaci√≥n. En este apartado veremos los siguientes:\n","\n","* Coeficiente de correlaci√≥n de Spearman.\n","\n","* Coeficiente de Kendall.\n","\n","* Coeficiente Chi-cuadrado.\n","\n","* Coeficiente de contingencia.\n"]},{"cell_type":"markdown","metadata":{"id":"r92xwqrAbBFs"},"source":["### 4.4.1. Coeficiente de correlaci√≥n de Spearman\n","\n","Cuando tengamos atributos ordinales, es posible ordenar sus categor√≠as y asignarles valores ordinales, de manera que se puede calcular el coeficiente de correlaci√≥n lineal entre estos valores ordinales. Se nota por $\\rho_{S}$ o bien $r_{s}$.\n","\n","Es decir, este coeficiente **es una medida de asociaci√≥n lineal que utiliza los rangos** y n√∫meros de orden, de cada grupo de sujetos y compara dichos rangos. \n","\n","Esta medida de relaci√≥n entre el orden que ocupan las categor√≠as de dos atributos ordinales se conoce como **coeficiente de correlaci√≥n de Spearman.** Tambi√©n llamado **rho de Spearman**.\n","\n","Con este coeficiente, se mide la fuerza y la direcci√≥n de la asociaci√≥n entre dos variables clasificadas, el mismo concepto que la correlaci√≥n lineal de Pearson vista anteriormente.\n","\n","Si tenemos una muestra de $ùëõ$ individuos en los que se han medido dos atributos ordinales $ùëã$ e $ùëå$, la f√≥rmula del coeficiente de correlaci√≥n de Spearman es:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   r_{s} = 1 - \\frac{6 \\sum_{i=1}^{n} d_{i}^2} { n (n^2-1)}  \n","} $$ \n","\n","Donde:\n","\n","* $n$ = n√∫mero de puntos de datos de las dos variables.\n","* $d_{i}$= diferencia de rango del elemento $n$.\n","\n","\n","Este coeficiente determina si existe relaci√≥n entre dos variables, y toma valores entre -1 y 1. Por tanto, **cumple la siguiente condici√≥n**:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  -1 \\leq r_{s} \\leq 1  \n","} $$ \n","\n","<br>\n","\n","<u><b> Interpretaci√≥n del coeficiente de Spearman </u></b>\n","\n","El resultado obtenido del coeficiente de correlaci√≥n de Spearman lo debemos interpretar de la siguiente manera:\n","\n","* Si $r_{s} = ‚àí1$ √≥ $r_{s} \\approx ‚àí1$, entonces los √≥rdenes de los atributos est√°n invertidos y existe una **relaci√≥n inversa perfecta**.\n","\n","* Si $r_{s} = 0$ √≥ $r_{s} \\approx 0$, entonces **no existe relaci√≥n** entre los atributos ordinales.\n","\n","* Si $r_{s} = 1$ √≥ $r_{s} \\approx 1$, entonces los √≥rdenes de los atributos coinciden y existe una **relaci√≥n directa perfecta.**\n","\n","* Hay relaci√≥n mon√≥tona perfecta cuando: $r_{s} = -1 $ (mon√≥tona decreciente) o bien  $r_{s} = 1$ (mon√≥tona creciente).\n","\n","* El coeficiente de Spearman es **invariante** ante transformaciones mon√≥tonas.\n","\n","* El coeficiente de Spearman es una medida de **dependencia mon√≥tona** entre $X$ e $Y$.\n","\n","* Si $X$ e $Y$ son independientes, entonces $r_{s} = 0$, aunque la condici√≥n inversa no tiene por qu√© ser cierta. S√≥lo cumple la inversa cuando el par ($X,Y$) sigue una normal bivariante.\n","\n","En general, cuanto m√°s cerca de 1 o ‚àí1 est√© $r_{s}$, mayor ser√° la relaci√≥n entre los atributos, y cuanto m√°s cerca de 0, menor ser√° la relaci√≥n.\n","\n","\n","<br>\n","\n","<u><b> Interpretaci√≥n gr√°fica </u></b> \n","\n","La representaci√≥n del valor del coeficiente de correlaci√≥n de Spearman es una gr√°fica en la que se aprecian los distintos tipos de monoton√≠a. Esto es:\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<table style=\"text-align: center;\" border=\"1\">\n","<tbody><tr>\n","<td><a href=\"//commons.wikimedia.org/wiki/File:Monotonicity_example1.png\" class=\"image\"><img alt=\"Monotonicity example1.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Monotonicity_example1.png/200px-Monotonicity_example1.png\" decoding=\"async\" data-file-width=\"1282\" data-file-height=\"1235\" width=\"200\" height=\"193\"></a>\n","<br>Funci√≥n mon√≥tona creciente: $r_{s} \\approx 1 $.\n","</td>\n","<td><a href=\"//commons.wikimedia.org/wiki/File:Monotonicity_example2.png\" class=\"image\"><img alt=\"Monotonicity example2.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Monotonicity_example2.png/200px-Monotonicity_example2.png\" decoding=\"async\" data-file-width=\"1282\" data-file-height=\"1235\" width=\"200\" height=\"193\"></a>\n","<br>Funci√≥n mon√≥tona decreciente: $r_{s} \\approx -1 $.\n","</td>\n","<td><a href=\"//commons.wikimedia.org/wiki/File:Monotonicity_example3.png\" class=\"image\"><img alt=\"Monotonicity example3.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Monotonicity_example3.png/200px-Monotonicity_example3.png\" decoding=\"async\" data-file-width=\"1282\" data-file-height=\"1235\" width=\"200\" height=\"193\"></a>\n","<br>Funci√≥n no mon√≥tona.:$r_{s} \\approx 0 $.\n","</td></tr></tbody></table>\n","</center>\n","</figure>\n","<center>\n","<figcaption>Imagen16. Interpretaci√≥n del Coeficiente de Correlaci√≥n Lineal de Pearson </figcaption></center>\n","\n","Fuente de la imagen: [www.en.wikipedia.org](https://es.wikipedia.org/wiki/Funci%C3%B3n_mon%C3%B3tona)\n","\n","\n","<br>\n","\n","<u><b> Relaci√≥n entre el coeficiente de Spearman y el de Pearson </u></b>\n","\n","El coeficiente de correlaci√≥n de Spearman es exactamente el mismo que el coeficiente de correlaci√≥n de Pearson pero calculado sobre el rango de observaciones. \n","\n","La correlaci√≥n estimada entre $X$ e $Y$ la hallamos calculando el coeficiente de correlaci√≥n de Pearson para el conjunto de rangos apareados. \n","\n","La correlaci√≥n de Spearman puede ser calculada con la f√≥rmula de Pearson, si antes hemos transformado las puntuaciones en rangos.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9WNs96BPHRwO"},"source":["### 4.4.2. Coeficiente de correlaci√≥n de Kendall\n","\n","\n","**El coeficiente de correlaci√≥n simple por rangos de Kendall** es una medida de dependencia no param√©trica que mide **el grado de asociaci√≥n entre las variables** y, al igual que la de Spearman, es utilizada para **medir la asociaci√≥n ordinal** entre dos cantidades medidas. Tambi√©n, recibe el nombre de _Tau de Kendall_ o _Coeficiente Tau_. Se denota por $\\tau$.\n","\n","En otras palabras, asignamos una clasificaci√≥n a las observaciones de cada variable y estudiamos la relaci√≥n de dependencia entre dos variables dadas. \n","\n","Para calcularlo, primero se ordenan las variables (de preferencia en orden ascendente) y luego se aplica el coeficiente de Kendall.\n","\n","Su f√≥rmula es la siguiente:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\tau = \\frac{n_{c} - n_{d}} {\\frac{1}{2} n (n-1)}  \n","} $$ \n","\n","Donde:\n","\n","* $n $ = es el n√∫mero de puntos de datos de las dos variables.\n","* $n_{c}$ = es el n√∫mero de pares concordantes.\n","* $n_{d}$ = es el n√∫mero de pares discordantes.\n","\n","Teniendo en cuenta que un par de datos $(x_{1}, y_{1})$ y $(x_{2}, y_{2})$ son:\n","\n","* **Concordantes** si cumplen:\n","  $$x_{1} < x_{2} \\quad \\text{y} \\quad y_{1} < y_{2}\n","   \\quad \\text{o bien}\\quad x_{1} > x_{2} \\quad \\text{y} \\quad  y_{1} > y_{2}\n","  $$\n","\n","* **Disconcordantes** si cumplen:\n","  $$x_{1} < x_{2} \\quad \\text{y} \\quad y_{1} > y_{2}\n","   \\quad \\text{o bien}\\quad x_{1} > x_{2} \\quad \\text{y} \\quad  y_{1} < y_{2}\n","  $$\n","\n","\n","Este coeficiente determina si existe relaci√≥n entre dos variables, y toma valores entre -1 y 1, por tanto **cumple la siguiente condici√≥n**:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  -1 \\leq  \\tau \\leq 1  \n","} $$ \n","\n","\n","<br>\n","\n","<u><b> Interpretaci√≥n del coeficiente de Kendall: </u></b>\n","\n","El coeficiente de correlaci√≥n por rangos de Kendall presenta las siguientes propiedades:\n","\n","* Siempre toma valores $ -1 \\leq  \\tau \\leq 1 $ por lo que:\n","\n","  * Si $\\tau = -1$ √≥ $\\tau \\approx -1$, indica relaci√≥n mon√≥tona negativa.\n","  * Si $\\tau = 0$ √≥ $\\tau \\approx 0 $, indica que no hay relaci√≥n mon√≥tona.\n","  * Si $\\tau = 1$ √≥ $\\tau \\approx 1 $, indica relaci√≥n mon√≥tona positiva.\n","\n","* Hay relaci√≥n mon√≥tona perfecta cuando: $\\tau = -1 $ (mon√≥tona decreciente) o bien  $\\tau = 1$ (mon√≥tona creciente).\n","\n","* La $\\tau$ es **invariante** ante transformaciones mon√≥tonas.\n","\n","* La $\\tau$ de Kendall es una medida de **dependencia mon√≥tona** entre $X$ e $Y$.\n","\n","* Si $X$ e $Y$ son independientes entonces $\\tau = 0$, aunque la condici√≥n inversa no tiene por qu√© ser cierta.\n","\n","* Si el par ($X,Y$) siguen una normal bivariante, entonces: $X$ e $Y$ son independientes  $\\Leftrightarrow \\tau = 0$.\n","\n","<br>\n","\n","<u><b> Interpretaci√≥n gr√°fica </u></b> \n","\n","La representaci√≥n del valor del coeficiente de correlaci√≥n $\\tau$ de Kendall en una gr√°fica nos permite apreciar los distintos tipos de monoton√≠a. Esto es:\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<table style=\"text-align: center;\" border=\"1\">\n","<tbody><tr>\n","<td><a href=\"//commons.wikimedia.org/wiki/File:Monotonicity_example1.png\" class=\"image\"><img alt=\"Monotonicity example1.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Monotonicity_example1.png/200px-Monotonicity_example1.png\" decoding=\"async\" data-file-width=\"1282\" data-file-height=\"1235\" width=\"200\" height=\"193\"></a>\n","<br>Funci√≥n mon√≥tona creciente: $\\tau \\approx 1 $.\n","</td>\n","<td><a href=\"//commons.wikimedia.org/wiki/File:Monotonicity_example2.png\" class=\"image\"><img alt=\"Monotonicity example2.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Monotonicity_example2.png/200px-Monotonicity_example2.png\" decoding=\"async\" data-file-width=\"1282\" data-file-height=\"1235\" width=\"200\" height=\"193\"></a>\n","<br>Funci√≥n mon√≥tona decreciente: $\\tau \\approx -1 $.\n","</td>\n","<td><a href=\"//commons.wikimedia.org/wiki/File:Monotonicity_example3.png\" class=\"image\"><img alt=\"Monotonicity example3.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Monotonicity_example3.png/200px-Monotonicity_example3.png\" decoding=\"async\" data-file-width=\"1282\" data-file-height=\"1235\" width=\"200\" height=\"193\"></a>\n","<br>Funci√≥n no mon√≥tona.:$\\tau \\approx 0 $.\n","</td></tr></tbody></table>\n","</center>\n","</figure>\n","<center>\n","<figcaption>Imagen17. Interpretaci√≥n del coeficiente de Kendall </figcaption></center>\n","\n","Fuente de la imagen: [www.en.wikipedia.org](https://es.wikipedia.org/wiki/Funci%C3%B3n_mon%C3%B3tona)\n","\n","<br>\n","\n","<u><b> Consideraciones </u></b>\n","\n","El coeficiente de correlaci√≥n $\\tau$ de Kendall es no param√©trico, es decir, se puede usar cuando no se cumple el supuesto de distribuci√≥n normal de las variables a comparar. \n","\n","La correlaci√≥n $\\tau$ de Kendall es particularmente adecuada cuando tenemos un **dataset de datos peque√±os con muchos valores en el mismo rango o clase**. Se puede usar con datos categ√≥ricos codificados binariamente (0,1). \n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","Estudios estad√≠sticos han demostrado que el coeficiente de correlaci√≥n $\\tau$ de Kendall es un mejor estimador de la correlaci√≥n en la poblaci√≥n que el coeficiente de correlaci√≥n no param√©trico de Spearman, por lo que **se recomienda** usar $\\tau$ **para an√°lisis de datos no param√©tricos**.\n","\n","El c√°lculo de la $\\tau$ de Kendall es ligeramente m√°s complejo que su hom√≥logo de Spearman.\n","\n","<br>\n","<p> <mark>SAB√çAS QUE...</mark> </p>\n","<hr>\n","\n","Tanto Kendall como Spearman, tienen una relaci√≥n con el coeficiente de Pearson."]},{"cell_type":"markdown","metadata":{"id":"011UsSrNH8Nk"},"source":["### 4.4.3. Chi-cuadrado\n","\n","Cuando queremos estudiar la relaci√≥n entre atributos nominales, no tiene sentido calcular el coeficiente de correlaci√≥n de Spearman ya que **las categor√≠as no pueden ordenarse**.\n","\n","Para estudiar la relaci√≥n entre atributos nominales, se utilizan medidas **basadas en las frecuencias** de la tabla de frecuencias bidimensional, que para atributos se suele llamar ***tabla de contingencia.***\n","\n","Es posible estudiar la relaci√≥n entre dos atributos $ùëã$ e $ùëå$ comparando las frecuencias reales con las esperadas a trav√©s de la tabla de contingencia, donde se estudia la diferencia entre las frecuencias observadas y las esperadas.\n","\n","**Para analizar la correlaci√≥n se usar√° el estad√≠stico chi-cuadrado**, cuya notaci√≥n es $\\chi^2$ y su f√≥rmula matem√°tica asociada es la siguiente:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\chi^2 = \\sum_{i=1}^{k}\\sum_{ji=1}^{p} \\frac{ (e_{ij}-n_{ij})^2 }{ e_{ij} }\n","} $$ \n","\n","\n","Donde:\n","\n","* $n_{ij}$ son las frecuencias observadas.\n","\n","* $e_{ij}$ son las frecuencias esperadas o te√≥ricas.\n","\n","<br>\n","\n","Si te fijas, **est√° elevado al cuadrado**, es decir, por ser suma de cuadrados, **cumple la siguiente condici√≥n**:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  \\chi^2 \\geq 0\n","} $$ \n","\n","<br>\n","\n","Teniendo en cuenta que: $ e_{ij} = (n_{i}.n_{.j})/n \\;$, si se sustituye en la f√≥rmula matem√°tica de la chi-cuadrado, entonces puede tener la expresi√≥n equivalente siguiente:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   \\chi^2 = n \\left[ \\sum_{i=1}^{k}\\sum_{ji=1}^{p} \\frac{ n_{ij}^2 }{ n_{i}.n_{.j}  } -1 \\right]\n","} $$ \n","\n","\n","\n","<br>\n","\n","<u><b> Interpretaci√≥n del chi-cuadrado: </u></b>\n","\n","El coeficiente de contingencias se rige por las mismas reglas de la correlaci√≥n vistas anteriormente, esto es:\n","\n","* Si $\\chi^2 = 0, $ implica que no hay correlaci√≥n o son independientes.\n","\n","* Si $\\chi^2 > 0, $ implica que existe la correlaci√≥n o asociaci√≥n.\n","\n","\n","En resumen, si $\\chi^2 = 0 $ entonces las variables son independientes, y a medida que aumenta el valor entonces crece la dependencia entre las variables.\n","\n","\n","<br>\n","\n","<u><b> Consideraciones de la chi-cuadrado </u></b>\n","\n","* **Si aumenta la muestra, aumenta el valor de chi-cuadrado**. Hay que tener cuidado con su interpretaci√≥n, ya que eso **no significa que haya m√°s correlaci√≥n**.\n","\n","*  Es necesario que se aplique a estudios basados en **muestras independientes.** \n","\n","* La prueba chi-cuadrado, a diferencia de otras pruebas, **no establece restricciones sobre el n√∫mero de modalidades por variables**, y no es necesario que el n√∫mero de filas y el n√∫mero de columnas de las tablas coincida.\n","\n","\n","* **No tiene un l√≠mite superior y no permite conocer la intensidad de la correlaci√≥n.** Dicho de otro modo, el chi-cuadrado toma valores entre 0 e infinito."]},{"cell_type":"markdown","metadata":{"id":"R8Ddy0xmHxPd"},"source":["### 4.4.4. Coeficiente de contingencia\n","\n","Como hemos mencionado anteriormente, uno de los inconvenientes del estad√≠stico **chi-cuadrado es que depende del tama√±o muestral**, ya que al multiplicar las frecuencias por una constante, su valor queda multiplicado por dicha constante. Esto podr√≠a inducir al equ√≠voco de pensar que ha aumentado la relaci√≥n, incluso cuando las proporciones se mantienen. Adem√°s, el valor de $\\chi^2$ no est√° acotado superiormente y **resulta dif√≠cil de interpretar**. \n","\n","Para **evitar todos estos inconvenientes** se suele utilizar el **Coeficiente de contingencia**, tambi√©n llamado **Coeficiente de contingencia de Karl Pearson** cuya notaci√≥n es $C$ o $K$ y su f√≥rmula es:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","   C = \\sqrt \\frac{ \\chi^2 }{ N+ \\chi^2 }\n","} $$ \n","\n","\n","Donde:\n","\n","* $\\chi^2$ es el valor del estad√≠stico chi-cuadrado.\n","\n","* $N$ es el n√∫mero total de la poblaci√≥n o la muestra.\n","\n","\n","Adem√°s, este estad√≠stico **cumple la siguiente condici√≥n**:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  0 \\leq C \\leq 1\n","} $$ \n","\n","\n","<br>\n","\n","<u><b> Interpretaci√≥n del Coeficiente de Contingencia: </u></b>\n","\n","* Si $C=0$, indica que no existe correlaci√≥n o asociaci√≥n. \n","\n","* Si $C=1$, indica que hay correlaci√≥n o asociaci√≥n completa.\n","\n","Por tanto, cuanto mayor es el coeficiente ($ C \\approx 1$) mayor ser√° la correlaci√≥n entre las variables.\n","\n","\n","<br>\n","\n","<u><b> Consideraciones del Coeficiente de Contingencia: </u></b>\n","\n","* El valor de $\\chi^2$ es necesario para determinar el coeficiente de contingencia $C$.\n","\n","* Aunque el coeficiente $C$ nunca puede llegar a valer 1; se puede demostrar que para tablas de contingencia con _$k$-filas_ y _$k$-columnas_, el valor m√°ximo que puede alcanzar el _coeficiente de contingencia_ es:\n","\n","$$ C = \\sqrt{\\frac{k-1}{k}} \\\\ $$\n","\n","\n","* En ocasiones, puede resultar problem√°tico que el l√≠mite superior del coeficiente de contingencia $C$ sea dependiente del n√∫mero de las dimensiones observadas ($N$). Para resolver dichos inconvenientes se usa el [Coeficiente de contingencia corregido](https://wikis.hu-berlin.de/mmint/Basics:_Relationship_between_Nominal_Variables_(Contingency)/es)."]},{"cell_type":"markdown","metadata":{"id":"Z2-zAshEpxSS"},"source":["## Actividad: Consumo hogar medio"]},{"cell_type":"markdown","metadata":{"id":"j7lVhCCe_f-i"},"source":["El dataset *propension_consumo.csv* contiene informaci√≥n de un hogar medio en el que aparecen los ingresos y el consumo realizados agrupados por el a√±o y el mes. \n","\n","**El objetivo es la b√∫squeda de un modelo matem√°tico** con la finalidad de explicar el consumo a partir de los datos facilitados."]},{"cell_type":"markdown","metadata":{"id":"FBWc0hGBjxgW"},"source":["### Soluci√≥n \n","\n","[*A continuaci√≥n, haz clic para conocer la soluci√≥n.*]"]},{"cell_type":"markdown","metadata":{"id":"RQ8N7DkyQOD1"},"source":["Lo primero que haremos, como siempre, es cargar el fichero para, despu√©s, analizar el tipo de variables con el que vamos a trabajar."]},{"cell_type":"code","metadata":{"id":"ixkODLtaYr-n","executionInfo":{"status":"ok","timestamp":1602173352578,"user_tz":-120,"elapsed":618,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"91628623-8637-43b5-dfad-1a0415511f4e","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["#Import libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Carga del fichero desde el enlace web y creaci√≥n del dataframe\n","url_data = 'https://raw.githubusercontent.com/md-lorente/data/master/propension_consumo.csv'\n","\n","# Creaci√≥n Dataframe\n","df_presupuestos = pd.read_csv(url_data, sep=';' , decimal=',' , encoding='utf-8')\n","\n","# Visualizaci√≥n del dataframe (la cabecera)\n","df_presupuestos.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>income</th>\n","      <th>consumption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2016</td>\n","      <td>1</td>\n","      <td>1078.132829</td>\n","      <td>945.960314</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2016</td>\n","      <td>2</td>\n","      <td>1082.953274</td>\n","      <td>951.257008</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2016</td>\n","      <td>3</td>\n","      <td>1089.776458</td>\n","      <td>953.184919</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2016</td>\n","      <td>4</td>\n","      <td>1095.929524</td>\n","      <td>957.322289</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2016</td>\n","      <td>5</td>\n","      <td>1102.322065</td>\n","      <td>963.698271</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   year  month       income  consumption\n","0  2016      1  1078.132829   945.960314\n","1  2016      2  1082.953274   951.257008\n","2  2016      3  1089.776458   953.184919\n","3  2016      4  1095.929524   957.322289\n","4  2016      5  1102.322065   963.698271"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"fjpP5eEhlsZO"},"source":["En primer lugar, antes de hacer el an√°lisis y ya que se trata de un nuevo dataset, analizaremos el tipo de variables con las que vamos a trabajar.\n","\n","Tanto income como expenses (ingresos y gastos) son variables cuantitativas de tipo continuo. Por otro lado, las variables year y month (a√±o y mes) son variables cualitativas de tipo ordinal."]},{"cell_type":"code","metadata":{"id":"3_SZE10kcjH-","executionInfo":{"status":"ok","timestamp":1602173355210,"user_tz":-120,"elapsed":753,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"87995ccb-f89d-4951-d4b0-a7c02f3ddf7e","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# raw data\n","ingreso = df_presupuestos[\"income\"] \n","consumo = df_presupuestos[\"consumption\"] \n","\n","# labels\n","plt.title(\"Distribuci√≥n de Ingresos VS Consumo\")\n","plt.xlabel(\"Ingresos\")\n","plt.ylabel(\"Consumo\")\n","\n","# limits\n","plt.xlim(ingreso.min()-1 , ingreso.max()+1 )\n","plt.ylim(consumo.min()-1 , consumo.max()+1 )\n","\n","plt.scatter(ingreso,consumo)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"xC3J5_1_lbZE"},"source":["Observa c√≥mo hay una l√≠nea recta \"imaginaria\" o \"invisible\" que pasa por las observaciones en la gr√°fica de dispersi√≥n. Esto hace que parezca que se trata de una recta de regresi√≥n lineal."]},{"cell_type":"code","metadata":{"id":"KDXAOevfkeKT","executionInfo":{"status":"ok","timestamp":1602173357664,"user_tz":-120,"elapsed":683,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"783d75cf-aeb5-4898-c2e7-17e0283175b3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["covarianza = df_presupuestos.cov()[\"income\"][\"consumption\"]\n","covarianza"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["220914.8051321471"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"aOPSE65vmgYZ"},"source":["Con la ***covarianza***, vemos que la relaci√≥n es positiva, es decir, presenta una relaci√≥n directa. Esto implica que a medida que aumentan los ingresos, hay una tendencia a que suban los gastos.\n","\n","Para ver si las variables est√°n ***correladas***, se hallar√° el coeficiente de correlaci√≥n lineal de Pearson."]},{"cell_type":"code","metadata":{"id":"e4gm3uuqnX1e","executionInfo":{"status":"ok","timestamp":1602173359521,"user_tz":-120,"elapsed":612,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"cd7518b1-b2c1-4530-82df-83e4e83f9407","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Correlacion \n","## Hay dos formas, con numpy es menos eficiente y visual\n","# correlacion = np.corrcoef(ingresos, gastos)\n","df_presupuestos.corr(method=\"pearson\")[\"income\"][\"consumption\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9941376840648395"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"XaE-zXIuoZug"},"source":["\n","El resultado del coeficiente de correlaci√≥n lineal de Pearson est√° pr√≥ximo a 1 lo que implica que existe una relaci√≥n lineal muy fuerte entre las variables analizadas de ingresos y gastos.\n","\n","Tambi√©n, podemos obtener el coeficiente de correlaci√≥n lineal de Pearson para m√°s de un par de elementos: **la matriz de correlaci√≥n**.\n","\n","√âsta extrae el valor para cada par de elementos, siendo el elemento consigo mismo la m√°xima correlaci√≥n y, por tanto, ser√° una matriz con la diagonal principal de valor 1. \n","\n","<br>\n","<p> <mark>PARA SABER M√ÅS</mark> </p>\n","<hr>\n","\n","Recomendamos la lectura del siguiente enlace para profundizar sobre la [matriz de correlaci√≥n](https://likegeeks.com/es/matrix-correlacion-python/)."]},{"cell_type":"code","metadata":{"id":"eufsgrbYnD1W","executionInfo":{"status":"ok","timestamp":1602173362494,"user_tz":-120,"elapsed":619,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"7beda65e-5bc9-4076-b839-436eb8ae6747","colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["# Matriz de correlaci√≥n\n","correlacion = df_presupuestos.corr()\n","correlacion"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>income</th>\n","      <th>consumption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>year</th>\n","      <td>1.000000</td>\n","      <td>-0.113547</td>\n","      <td>0.931396</td>\n","      <td>0.944754</td>\n","    </tr>\n","    <tr>\n","      <th>month</th>\n","      <td>-0.113547</td>\n","      <td>1.000000</td>\n","      <td>0.099310</td>\n","      <td>0.078407</td>\n","    </tr>\n","    <tr>\n","      <th>income</th>\n","      <td>0.931396</td>\n","      <td>0.099310</td>\n","      <td>1.000000</td>\n","      <td>0.994138</td>\n","    </tr>\n","    <tr>\n","      <th>consumption</th>\n","      <td>0.944754</td>\n","      <td>0.078407</td>\n","      <td>0.994138</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 year     month    income  consumption\n","year         1.000000 -0.113547  0.931396     0.944754\n","month       -0.113547  1.000000  0.099310     0.078407\n","income       0.931396  0.099310  1.000000     0.994138\n","consumption  0.944754  0.078407  0.994138     1.000000"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"bEFdlY5uGIE5","executionInfo":{"status":"ok","timestamp":1602173364714,"user_tz":-120,"elapsed":735,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"bc0f1bec-7c67-41ed-8055-04df2b907628","colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["# Se puede visualizar mejor los valores correlados fuertemente (rojo) \n","# frente con los correlados d√©bilmente (en azul) similar a un \"mapa de calor\"\n","correlacion.style.background_gradient(cmap='coolwarm').set_precision(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<style  type=\"text/css\" >\n","#T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col0,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col1,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col2,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col3{\n","            background-color:  #b40426;\n","            color:  #f1f1f1;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col1,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col0,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col2,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col3{\n","            background-color:  #3b4cc0;\n","            color:  #f1f1f1;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col2{\n","            background-color:  #cf453c;\n","            color:  #f1f1f1;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col3,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col0{\n","            background-color:  #ca3b37;\n","            color:  #f1f1f1;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col1{\n","            background-color:  #779af7;\n","            color:  #000000;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col3,#T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col2{\n","            background-color:  #b50927;\n","            color:  #f1f1f1;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col0{\n","            background-color:  #c53334;\n","            color:  #f1f1f1;\n","        }#T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col1{\n","            background-color:  #7295f4;\n","            color:  #000000;\n","        }</style><table id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >year</th>        <th class=\"col_heading level0 col1\" >month</th>        <th class=\"col_heading level0 col2\" >income</th>        <th class=\"col_heading level0 col3\" >consumption</th>    </tr></thead><tbody>\n","                <tr>\n","                        <th id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >year</th>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1.000</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col1\" class=\"data row0 col1\" >-0.114</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.931</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.945</td>\n","            </tr>\n","            <tr>\n","                        <th id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >month</th>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col0\" class=\"data row1 col0\" >-0.114</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1.000</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0.099</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0.078</td>\n","            </tr>\n","            <tr>\n","                        <th id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >income</th>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.931</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.099</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1.000</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0.994</td>\n","            </tr>\n","            <tr>\n","                        <th id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >consumption</th>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0.945</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.078</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.994</td>\n","                        <td id=\"T_a193e000_0980_11eb_b8c0_0242ac1c0002row3_col3\" class=\"data row3 col3\" >1.000</td>\n","            </tr>\n","    </tbody></table>"],"text/plain":["<pandas.io.formats.style.Styler at 0x7f41a3172748>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"IMst_nzvJfuL"},"source":["Ajuste lineal\n","\n","* El objetivo es buscar un modelo lineal que se ajuste a las observaciones del dataset y que permita hacer predicciones. En este caso, *se trata de predecir el consumo.*\n","\n","* Se puede generar una funci√≥n a partir de los conceptos de la media, la varianza, y la covarianza. Recordemos la f√≥rmula asociada a la recta de regresi√≥n de $Y$ sobre $X$:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  y - \\widehat{y} = \\frac{\\sigma_{xy}} { \\sigma_{x}^2 } (x - \\widehat{x}) }$$ "]},{"cell_type":"code","metadata":{"id":"Lgqxn5wcozi2","executionInfo":{"status":"ok","timestamp":1602173370286,"user_tz":-120,"elapsed":3174,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"80aa25b0-fdd6-49d5-bb37-731213c28dc3","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# Ajuste lineal\n","# Recta de Regresi√≥n Y sobre X\n","def recta(x):\n","    pendiente = df_presupuestos.cov()[\"income\"][\"consumption\"]/df_presupuestos[\"income\"].var()\n","    return pendiente*(x-df_presupuestos[\"income\"].mean())+df_presupuestos[\"consumption\"].mean()\n","\n","line = [recta(x) for x in np.arange(3000)]\n","\n","# labels\n","plt.title(\"Distribuci√≥n de ingresos VS gastos\")\n","plt.xlabel(\"Ingresos\")\n","plt.ylabel(\"Consumo\")\n","\n","# limits\n","plt.xlim(df_presupuestos[\"income\"].min() , df_presupuestos[\"income\"].max() )\n","plt.ylim(df_presupuestos[\"consumption\"].min() , df_presupuestos[\"consumption\"].max() )\n","\n","# Nube de puntos + recta de regresi√≥n\n","plt.scatter(df_presupuestos[\"income\"],df_presupuestos[\"consumption\"])\n","plt.plot(line, color='red')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"nxBHPR2zqT2A"},"source":["Como observaci√≥n, la parte estad√≠stica de *SciPy* (vista anteriormente) tiene un **m√©todo mucho m√°s r√°pido y eficiente que obtiene el mismo resultado.**\n","\n","<br>\n","<p> <mark>PARA SABER M√ÅS</mark> </p>\n","<hr>\n","\n","Recomendamos la lectura del siguiente enlace:\n","\n","[www.docs.scipy.org](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)\n","\n","Veamos c√≥mo aplicarlo en este caso:"]},{"cell_type":"code","metadata":{"id":"0cY25ONAquUQ","executionInfo":{"status":"ok","timestamp":1602173374032,"user_tz":-120,"elapsed":834,"user":{"displayName":"instituto forymat","photoUrl":"","userId":"17895787503402093384"}},"outputId":"8a934fb3-c520-4f80-b7ba-1f5acc235ac5","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["from scipy import stats as ss\n","\n","#linregress es el metodo para extraer la recta\n","pendiente, coeficiente, pearson, p, error = ss.linregress(df_presupuestos[\"income\"],df_presupuestos[\"consumption\"])\n","\n","def recta(x):\n","    return coeficiente + pendiente*x\n","\n","recta = np.vectorize(recta)\n","linea = recta(np.arange(3000))\n","\n","# labels\n","plt.title(\"Distribuci√≥n de Ingresos VS el Consumo\")\n","plt.xlabel(\"Ingresos\")\n","plt.ylabel(\"Consumo\")\n","\n","# limits\n","plt.xlim(df_presupuestos[\"income\"].min() , df_presupuestos[\"income\"].max() )\n","plt.ylim(df_presupuestos[\"consumption\"].min() , df_presupuestos[\"consumption\"].max() )\n","\n","# Nube de puntos + recta de regresi√≥n\n","plt.scatter(df_presupuestos[\"income\"],df_presupuestos[\"consumption\"])\n","colores= ['blue', 'red']\n","plt.plot(df_presupuestos[\"income\"], df_presupuestos[\"consumption\"], 'o' )\n","plt.plot(linea , color='red')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"iF35bKzPuFzf"},"source":["Como Pearson nos da un n√∫mero muy pr√≥ximo a 1 (0.9941), se puede definir un modelo matem√°tico a trav√©s de la regresi√≥n lineal."]},{"cell_type":"code","metadata":{"id":"dACyXuzjuY9u"},"source":["# Modelo matem√°tico\n","pendiente, coeficiente, pearson, p, error = ss.linregress(df_presupuestos[\"income\"], df_presupuestos[\"consumption\"])\n","\n","def consumption(income):\n","    return coeficiente + income*pendiente"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w62sPviUum0K"},"source":["Con esta funci√≥n se define un modelo capaz de predecir los gastos a partir de los nuevos ingresos obtenidos y la pendiente de la recta, asumiendo un error aleatorio.\n","\n","Este modelo matem√°tico se corresponde con la **funci√≥n de gasto en consumo** o m√°s conocida en econom√≠a como [funci√≥n de consumo](http://www.economia48.com/spa/d/funcion-de-consumo/funcion-de-consumo.htm). Se usa para determinar el gasto de los consumidores.\n","\n","<br>\n","<p> <mark>PARA SABER M√ÅS</mark> </p>\n","<hr>\n","\n","\n","Para profundizar m√°s en la  _funci√≥n de consumo_ recomendamos la lectura de:\n","\n","* [Funci√≥n de consumo.](https://www.auladeeconomia.com/macro-material2.htm)\n","\n","* [Modelo de Keynesiano.](https://www.auladeeconomia.com/articulos2.htm#keynes)\n","\n","Puedes obtener m√°s informaci√≥n en el siguiente enlace: [www.auladeeconomia.com](https://www.auladeeconomia.com/index.htm) (en la secci√≥n de _macroeconom√≠a_).\n","\n","Dicha funci√≥n se corresponde con una *regresi√≥n lineal* que se expresa como:\n","\n","$$ \\bbox[5px,border: 2px solid blue]{ \n","  C = \\beta_{0} + \\beta_{1} Y_{d} }$$\n","\n","donde:\n","\n","* C = Consumo privado.\n","* $\\beta_{0}$ = Consumo aut√≥nomo.\n","* $\\beta_{1}$ = Propensi√≥n marginal a consumir.\n","* $Y_{d}$ = Nivel de ingreso disponible.\n","\n","<br>\n","<p> <mark>OBSERVACIONES</mark> </p>\n","<hr>\n","\n"," * En algunos sitios (o libros) sustituyen las letras griegas por letras del alfabeto espa√±ol (o ingl√©s) con el fin de simplificar la f√≥rmula de la funci√≥n de consumo.\n"," * Se aclara, tambi√©n, que el nivel de consumo no depende del nivel de ingreso directamente, sino que se ha llamado \"ingreso\" para englobar otros factores como las tasas de inter√©s Y la disponibilidad crediticia, entre otros."]},{"cell_type":"markdown","metadata":{"id":"fCEAHetVKufX"},"source":["# **IDEAS CLAVE**\n","<br>\n","<hr>\n","<p> <h1> <center> <strong> Regresi√≥n y Correlaci√≥n </center> </strong> </h1> </p>\n","<hr>\n","<br> \n","\n","*   Se pueden realizar **inferencias o predicciones a trav√©s de las rectas de regresi√≥n.**\n","\n","\n","*   **La correlaci√≥n no implica causalidad,** se debe de analizar para realizar una interpretaci√≥n correcta de los datos.\n","\n","*   **Siempre hay que analizar la robustez del modelo a trav√©s de la bondad de ajuste y de la correlaci√≥n.** En funci√≥n del tipo de variables del modelo de estudio, la correlaci√≥n se estudiar√° con el coeficiente de correlaci√≥n lineal de Pearson, de Spearman, Kendall, chi-cuadrado o el de contingencia.\n","\n","* Para aquellas **regresiones que no sean de tipo lineal se buscar√° una transformaci√≥n** para \"linealizar\" la expresi√≥n matem√°tica y simplificar as√≠ el c√°lculo.\n"]}]}